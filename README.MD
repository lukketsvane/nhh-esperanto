# NHH Esperanto - Language Learning Experiment Dataset

**Final Consolidated Dataset** - All 604 survey responses with matched ChatGPT conversation data

## ğŸ‰ Dataset Complete - 604 Entries Ready for Analysis!

**Major Achievement**: Successfully recovered 361 participants (92.8% of matches) who forgot to state their ID!

### Quick Stats
- âœ… **604 total entries** (all survey responses)
- âœ… **389 matched** (64.4%) with ChatGPT conversation data
- âœ… **361 participants who forgot their ID** - successfully recovered via timestamp matching!
- âœ… **20 additional conversations** recovered from old data exports
- âœ… **98.0% match success rate** of all available conversations

### Main Dataset File
ğŸ“Š **`data/processed/nhh_esperanto_final_consolidated_dataset.csv`** (3.29 MB)

See [FINAL_DATASET_DOCUMENTATION.md](FINAL_DATASET_DOCUMENTATION.md) for complete documentation.

## Repository Structure

```
nhh-esperanto/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # Raw input data files
â”‚   â”‚   â”œâ”€â”€ iverdata.csv         # Survey responses (604)
â”‚   â”‚   â””â”€â”€ unified_conversation_data_complete.csv  # All conversations (397)
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/                # Final processed datasets
â”‚   â”‚   â”œâ”€â”€ nhh_esperanto_final_consolidated_dataset.csv  # ğŸ”‘ MAIN DATASET (604 entries)
â”‚   â”‚   â”œâ”€â”€ nhh_esperanto_participants.csv      # Participant demographics
â”‚   â”‚   â”œâ”€â”€ nhh_esperanto_conversations.csv     # Conversation metadata
â”‚   â”‚   â”œâ”€â”€ nhh_esperanto_messages.csv          # Individual messages
â”‚   â”‚   â”œâ”€â”€ nhh_esperanto_data_dictionary.csv   # Variable descriptions
â”‚   â”‚   â”œâ”€â”€ recovered_conversation_messages.csv # Recovered data (366 messages)
â”‚   â”‚   â”œâ”€â”€ recovered_matches.csv               # Recovery match details (20 matches)
â”‚   â”‚   â””â”€â”€ DATASET_SUMMARY.txt                 # Quick statistics
â”‚   â”‚
â”‚   â””â”€â”€ old/                      # Archive of historical data exports
â”‚       â””â”€â”€ Unified_CSN_Data_-_16-12-2024.csv  # Source of recovered data
â”‚
â”œâ”€â”€ scripts/                    # Processing and recovery scripts
â”‚   â”œâ”€â”€ create_final_consolidated_dataset.py  # â­ Creates final 604-entry dataset
â”‚   â”œâ”€â”€ cleanup_old_files.py                  # Cleans up old files
â”‚   â”œâ”€â”€ regenerate_ids_and_verify.py          # Extracts/generates participant IDs
â”‚   â”œâ”€â”€ extract_using_ast.py                  # Recovers data from CSN file
â”‚   â”œâ”€â”€ match_recovered_conversations.py      # Matches recovered conversations
â”‚   â””â”€â”€ README.md                             # Scripts documentation
â”‚
â”œâ”€â”€ explorer/                   # Data exploration app (Next.js)
â”‚
â”œâ”€â”€ FINAL_DATASET_DOCUMENTATION.md  # ğŸ“Š Complete dataset documentation
â”œâ”€â”€ RECOVERY_VERIFICATION_REPORT.md # Recovery verification details
â”œâ”€â”€ FINAL_MATCHING_REPORT.md        # Matching methodology
â””â”€â”€ README.MD                        # This file
```

## Dataset Description

This dataset documents an experiment where participants were assigned to different treatment groups while learning Esperanto:

- **Control**: No AI assistance
- **AI-assisted**: Basic AI assistance for answering questions
- **AI-guided**: Enhanced AI assistance with structured guidance and exercises

The experiment measured how different forms of AI assistance affect language learning, confidence, motivation, and other metrics.

## Key Variables

### Participant Variables
- `final_id`: Participant ID
- `treatment_clean`: Treatment group (Control, AI-assisted, AI-guided)
- `gender`: Participant gender
- `highgpa`: Binary indicator for high GPA
- `testscore`: Score on Esperanto language test
- `index_confidence`, `index_motivation`, `index_complement`, `index_cheating`: Psychological indices

### Conversation Metrics
- `MessageCount`: Total messages exchanged
- `UserMessageCount`: Number of user messages
- `AIMessageCount`: Number of AI messages
- `ConversationDurationMinutes`: Duration in minutes
- `AverageUserMessageLength`: Average characters per user message
- `AverageAIMessageLength`: Average characters per AI message

## Data Recovery & Processing Pipeline

Our data processing pipeline successfully recovered participants who forgot to state their ID and matched them to their conversations.

### Recovery Process

**The Challenge**: 361 out of 389 matched participants (92.8%) forgot to state their ID in the introductory ChatGPT message!

**The Solution**:
1. **ID Extraction** (`regenerate_ids_and_verify.py`): Extracted IDs from messages using multiple regex patterns
2. **Timestamp Matching**: Matched conversations to surveys using temporal proximity (24-hour tolerance)
3. **ID Generation**: Generated IDs from timestamps for those who forgot: `DDMMYYYY_HHMM` format
4. **Data Recovery** (`extract_using_ast.py`): Found 21 additional conversations in old CSN export
5. **AST Parsing Breakthrough**: Used `ast.literal_eval()` to parse Python dict strings (not JSON!)
6. **Additional Matching** (`match_recovered_conversations.py`): Matched 20/21 recovered conversations

**The Results**:
- âœ… **361 participants who forgot their ID successfully recovered!**
- âœ… **20 additional matches from recovered data**
- âœ… **98.0% match success rate** (of available conversations)
- Only 8 unused conversations (all "Login assistance" test messages)

### Core Processing Steps

#### 1. Data Merging (`merge_datasets.py`)

Merges survey responses with conversation logs:
- Matches participants across datasets using ID patterns and timestamps
- Extracts conversation metrics
- Identifies unmatched records for review
- Computes match confidence scores

#### 2. Data Enhancement (`enhance_dataset.py`)

Improves the merged dataset:
- Fixes encoding issues and standardizes formats
- Improves user identification
- Creates derived metrics
- Splits the data into normalized tables
- Generates a data dictionary

#### 3. ID Regeneration (`regenerate_ids_and_verify.py`) â­

Extracts and generates participant IDs:
- Extracts IDs from conversation messages using regex
- Generates IDs from timestamps for those who forgot
- Result: 291 extracted, 78 generated

#### 4. Data Recovery (`extract_using_ast.py`) â­

Recovers conversations from old CSN export:
- Uses `ast.literal_eval()` to parse Python dictionary strings
- Extracts 366 messages from 21 conversations
- Enables matching of previously inaccessible data

## Running the Data Processing Scripts

### Quick Start (Use Existing Processed Data)

The repository already contains fully processed and matched data:
- **Main dataset**: `data/processed/nhh_esperanto_finalized_dataset.csv`
- **Participant data**: `data/processed/nhh_esperanto_participants.csv`
- **Conversation data**: `data/processed/nhh_esperanto_conversations.csv`
- **Message data**: `data/processed/nhh_esperanto_messages.csv`

### Full Processing Pipeline (From Scratch)

To reproduce the entire processing and recovery pipeline:

```bash
# Create necessary directories if they don't exist
mkdir -p data/raw data/processed

# 1. Merge survey data with conversation logs
python scripts/merge_datasets.py

# 2. Enhance the merged dataset
python scripts/enhance_dataset.py

# 3. Extract and generate participant IDs (KEY STEP!)
python scripts/regenerate_ids_and_verify.py

# 4. Extract recovered conversations from old CSN file
python scripts/extract_using_ast.py

# 5. Match recovered conversations to surveys
python scripts/match_recovered_conversations.py

# 6. (Optional) Run additional recovery attempts
python scripts/aggressive_rematching.py
python scripts/fix_cross_date_mismatches.py
```

See [scripts/README.md](scripts/README.md) for detailed documentation of all scripts.

## Data Explorer Application

The repository includes a Next.js application for exploring and visualizing the dataset.

To set up and run the explorer:

```bash
# 1. Install dependencies
cd explorer
npm install --legacy-peer-deps

# 2. Run the development server
npm run dev
```

### Explorer Architecture

The data explorer uses a client-server architecture:

1. **Server-side**: 
   - API endpoints under `/api/data` read CSV files from the filesystem
   - Serves data to the client for visualization and exploration

2. **Client-side**:
   - Interactive data tables with filtering and pagination
   - Data visualization tools (charts, plots, etc.)
   - Statistical analysis and summary views

The explorer provides:
- Interactive data tables with filtering
- Visualizations (box plots, bar charts, histograms, scatter plots)
- Statistical summaries and frequency distributions
- Data export functionality

## License

[MIT License](LICENSE)